# スクレイピング実行ガイド

本プロジェクトでは、`netkeiba.com` から過去のレース結果データを収集するためのスクリプトを用意しています。
このガイドでは、スクリプトの使用方法と注意点を説明します。

## 1. 環境構築 (初回のみ)

スクリプトを実行する前に、Pythonの実行環境を整える必要があります。

### 1.1 仮想環境の作成
プロジェクト専用のPython環境（仮想環境）を作成します。これにより、他のプロジェクトとライブラリが競合するのを防ぎます。

```bash
# プロジェクトのルートディレクトリで実行
python -m venv .venv
```

### 1.2 仮想環境の有効化
作成した仮想環境を有効にします。

```bash
# Mac / Linux の場合
source .venv/bin/activate

# Windows (PowerShell) の場合
# .venv\Scripts\Activate.ps1
```

※ ターミナルの先頭に `(.venv)` と表示されれば成功です。

### 1.3 ライブラリのインストール
必要なライブラリ（`requests`, `beautifulsoup4`, `pandas` など）を一括でインストールします。

```bash
pip install -r requirements.txt
```

### 1.4 Playwrightのブラウザインストール (動的データ取得用)
JRA公式サイトなどの動的サイトを扱うために必要なブラウザバイナリをインストールします。

```bash
playwright install
```

## 2. スクリプトの実行

`src/data/scraper.py` を直接実行することで、データの収集を開始できます。

```bash
python -m src.data.scraper
```

### デフォルトの動作
現在のスクリプト (`src/data/scraper.py`) の `main` ブロックは、以下の動作をするように設定されています（デモ用）。

1.  **2023年1月** のカレンダーを取得。
2.  その月のレースIDリストを作成。
3.  **最初の3レースのみ** 詳細データを取得して保存。

## 3. 大量データを取得する場合の修正

過去数年分のデータを本格的に取得する場合は、`src/data/scraper.py` の `if __name__ == "__main__":` ブロックを以下のように修正してください。

```python
if __name__ == "__main__":
    scraper = NetkeibaScraper()
    
    # 例: 2018年から2023年までのデータを取得
    for year in range(2018, 2024):
        for month in range(1, 13):
            print(f"--- {year}年{month}月のデータを取得中 ---")
            
            # 1. その月の全レースIDを取得
            race_ids = scraper.scrape_race_calendar(year, month)
            
            # 2. 各レースの結果を取得
            for rid in race_ids:
                # 既にファイルが存在する場合はスキップされるので安心です
                scraper.scrape_race_result(rid)
                
                # サーバー負荷軽減のため、少し待機（スクレイパー内部でも1秒待機していますが、念のため）
                # time.sleep(0.5) 
```

## 4. データの保存場所

取得されたHTMLファイルは以下のディレクトリに保存されます。

*   `data/html/`
    *   `calendar_YYYYMM.html`: 月ごとのカレンダーページ
    *   `daily_YYYYMMDD.html`: 日ごとのレース一覧ページ
    *   `race_YYYYMMDDJJRR.html`: **レース結果ページ（これがメインのデータです）**

## 5. 注意事項

*   **中断と再開**: スクレイパーは、既に同名のファイルが存在する場合、ダウンロードをスキップします。そのため、途中でエラー等で止まっても、再度コマンドを実行すれば続きから再開できます。
*   **サーバー負荷**: `NetkeibaScraper` クラス内で、リクエスト毎に **1秒間の待機時間 (`time.sleep(1)`)** を設けています。この設定は**絶対に削除しないでください**。短時間に大量のリクエストを送ると、サイトへの攻撃とみなされ、IPアドレスがブロックされる可能性があります。
*   **データ量**: 1年分のデータで約3,500レース（ファイル数も同等）になります。ディスク容量には余裕を持ってください。
