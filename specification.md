競馬予測AIシステム仕様書

1.0 システム概要

1.1 目的

本仕様書は、競馬におけるリターンの長期的最大化を戦略目標として設計された、統合型自動投資プラットフォームの技術仕様を定義するものである。本システムは単なる予測ツールではなく、データ収集から機械学習による予測、期待値に基づく投資判断、そして最終的な馬券の自動購入まで、一連のプロセスを完全に自動化されたパイプラインとして実装する。

この目的を達成するため、本システムは以下の主要な目標を掲げる。

* データ駆動型の馬券購入: netkeiba.comやJRA公式サイトを含む複数の情報源から、レース、馬、騎手、血統に関するデータを体系的に自動収集・処理し、機械学習モデルの予測に基づいた客観的な馬券購入戦略を実行すること。  
* 期待値の最大化: モデルが算出する勝率とレース直前のリアルタイムオッズを掛け合わせ、各馬券の「期待値」を定量的に評価する。期待値が所定の閾値を超えた馬券のみに投資を限定することで、統計的優位性を確保し、長期的なリターンを最大化すること。  
* 運用の完全自動化: クラウド上のVPS（Virtual Private Server）を常時稼働環境とし、スケジュール実行（cron）を用いてレース開催日に全プロセスを無人で実行する体制を構築すること。これにより、手動介入を完全に排除し、運用の一貫性と信頼性を担保する。

本仕様書では、これらの目的を達成するためのシステムアーキテクチャ、技術的基盤、そして各サブシステムの詳細仕様について規定する。

1.2 主要機能

本システムのコア機能を明確に定義することは、開発の指針を定め、コンポーネントが戦略目標と整合していることを保証する設計図として機能する。本システムは、以下の3つの主要機能群から構成されるものとする。

* データ収集・処理機能  
  * Beautiful Soup、Selenium、Playwrightを駆使し、静的および動的なウェブサイト（netkeiba.com, JRA公式サイト）から、レース結果、馬の過去成績、騎手・調教師データ、血統データ、レース開催日程、レース直前オッズなどを体系的にスクレイピングする。  
  * 収集した生データ（HTML）および中間生成物（CSV）は、バージョン管理された一貫性のあるディレクトリ構造の下で、データセットとして体系的に保存・管理される。  
  * pandasライブラリを用い、収集したデータのクレンジング、データ型変換、欠損値処理、および予測精度向上を目的とした特徴量生成（過去Nレースの成績集計、レース条件別成績集計、レース内での相対的強さを示す標準化など）を実行する。  
* 機械学習による予測機能  
  * 勾配ブースティングアルゴリズムであるLightGBMを利用し、与えられた特徴量から各出走馬の「1着になる確率」を予測する機械学習モデルを構築する。  
  * 過去データを時系列に沿って学習・検証・テスト用に分割する。Optunaによるハイパーパラメータ最適化や早期停止（Early Stopping）などの手法を適用し、過学習を抑制することで、未知のデータに対する高い汎化性能を持つモデルを育成する。  
  * 学習済みモデルの性能をログロス（Log Loss）で定量的に評価し、バックテストを通じて期待値に基づく投票戦略の的中率および回収率をシミュレートする。  
* 自動投票・運用機能  
  * Playwrightを用いてJRAのIPATサイトへのログイン、レース選択、馬券種・馬番・金額の入力、購入といった一連の操作を自動化する。  
  * OSレベルのcron（粗粒度のスケジューラ）とアプリケーションレベルのAPSScheduler（細粒度のスケジューラ）を組み合わせた2層スケジューリングアーキテクチャを採用する。cronはレース開催日のマスター スクリプト起動を担い、APSSchedulerはレース発走時刻に紐づく精密なタイミングでのタスク（例：発走5分前からのオッズポーリング）を実行する。  
  * nohupコマンドによりSSHセッション切断後もプロセスのバックグラウンド実行を保証し、loggingモジュールを用いてシステムの全活動をファイルに永続的に記録する。

これらの機能を実現する技術的な基盤について、次章でさらに詳しく解説する。

1.3 システム構成とデータフロー

本セクションでは、データがシステム内をどのように流れ、処理され、最終的にアクション（投票）に至るかというエンドツーエンドのデータパイプラインを概説する。このフローを理解することは、システムの完全性の維持、ボトルネックの特定、および効果的な監視を可能にする上で不可欠である。

以下に、主要コンポーネント間のデータフローを示す。

1. データソース (Data Sources):  
* 主たる情報源はnetkeiba.com（過去のレース結果、成績、血統情報）およびJRA公式サイト（開催日程、レース直前オッズ）とする。補完的かつ安定的なデータソースとして、別インスタンスのConoHa for Windows Server上で稼働する有料ソフトウェアJRA-VANも利用し、特定のオッズ種別（単勝・複勝・枠連・馬連）を取得することでデータの冗長性を確保する。  
2. データ収集 (Data Acquisition \- VPS上):  
* スケジュール実行: cronが指定された日時にメインのPythonスクリプトを起動する。  
* スクレイピング: スクリプト内部でBeautiful SoupやPlaywrightが起動し、各データソースからHTMLデータを取得する。取得された生データはdata/html/ディレクトリ以下に体系的に保存される。  
3. データ処理と特徴量生成 (ETL & Feature Engineering):  
* 生データ加工: 収集したHTMLからpandasを用いて必要な情報を抽出し、整形済みCSVファイルとしてdata/common/raw\_data/に保存する。  
* 特徴量生成: 生データCSVを基に、pandasを用いて過去成績の集計や各種指標の計算を行い、モデルの学習および予測に使用する特徴量テーブル（features.csv）を生成する。このプロセス全体はバージョン管理される。  
4. モデル予測と投票判断 (Prediction & Decision):  
* 予測: 事前に学習済みのLightGBMモデル（.pklファイル）をロードし、当日のレースの特徴量データを入力して各馬の勝率を予測する。  
* 期待値計算: レース直前にPlaywrightを用いてJRA公式サイトから最新オッズを取得し、予測された勝率と掛け合わせることで各馬券の期待値を算出する。  
* 投票判断: 設定された期待値の閾値に基づき、購入すべき馬券（馬番、馬券種、金額）を最終的に決定する。  
5. 自動投票 (Automated Betting):  
* IPAT操作: PlaywrightがIPATサイトにログインし、ステップ4で決定された馬券情報を基に、一連の購入操作を自動的に実行する。  
6. ロギングと監視 (Logging & Monitoring):  
* 実行記録: loggingサブシステムは、データ収集から最終的な馬券購入までの全クリティカルな操作について、タイムスタンプ付きの永続的な監査証跡を提供する。これらのログは、レース後のパフォーマンス分析、デバッグ、およびシステムの運用健全性の検証に不可欠である。

これらのコンポーネントを支える具体的な技術要素については、次の技術スタックのセクションで詳述する。

2.0 技術スタック

本システムを構成する技術要素を一覧化することは、システムの全体像を技術的な観点から理解し、保守性や拡張性を評価する上で極めて重要である。以下に、採用している主要な技術スタックをカテゴリ別に示す。

カテゴリ	技術/ライブラリ	主要な用途 プログラミング言語	Python	全てのロジック開発の基盤言語 データ操作・分析	pandas	データフレーム操作、前処理、特徴量生成、集計 機械学習	LightGBM	1着予測モデルの構築 Optuna	LightGBMのハイパーパラメータ自動最適化 Webスクレイピング	Beautiful Soup	静的なHTMLページの解析とデータ抽出 Playwright	動的なJavaScriptサイトの操作、JRA公式サイトからのオッズ取得、IPAT自動投票 Selenium/ChromeDriver	補助的なブラウザ自動操作 タスクスケジューリング	APSScheduler (Python)	スクリプト内での詳細なタイミングでのタスク実行（例：レース直前の定期的なオッズ取得） cron (Linux)	レース開催日の朝にメインスクリプトを起動するなどのOSレベルでの定期実行 開発・実行環境	VSCode (Remote-SSH)	リモートサーバー上での統合開発環境 Jupyter Notebook	データ分析、実験、プロトタイピング 仮想環境 (venv)	Pythonのプロジェクトごとの依存関係の分離 テスト	pytest	データ整合性やロジックの単体テスト インフラストラクチャ	ConoHa VPS (Linux)	メインアプリケーションの実行サーバー ConoHa for Windows Server	JRA-VANなどWindows専用ソフトウェアの実行環境 運用ツール	argparse	スクリプト実行時のコマンドライン引数の管理 logging	実行ログのファイルへの永続的な記録 nohup	サーバーからの切断後もプロセスをバックグラウンドで継続実行

これらの技術が各サブシステムで具体的にどのように活用されているか、次のセクションで詳しく解説する。

3.0 サブシステム仕様

3.1 データ収集・処理

本サブシステムは、プラットフォーム全体の予測能力の基盤である。その設計は、データの完全性、網羅性、そして生のウェブデータからの予測シグナルの体系的な抽出を最優先事項とする。このレイヤーにおけるいかなる妥協も、システム全体のパフォーマンスと収益性を直接的に低下させるものと認識する。

* データソースと収集対象:  
  * netkeiba.com: モデルの根幹となる過去データを収集するための主要な情報源である。レース結果、馬・騎手・調教師・種牡馬の過去成績、血統情報、払い戻しテーブルなどを取得する。コンテンツの大半が静的であるため、リソースオーバーヘッドを最小化し高速なパースを実現するBeautiful Soupを主として使用する。  
  * JRA公式サイト: レース開催日程、出馬表、および最も重要なレース直前のリアルタイムオッズを収集する。これらのページはJavaScriptによって動的にコンテンツが生成されるため、ブラウザエミュレーションがデータアクセスに必須となるPlaywrightの使用を前提とする。  
  * JRA-VAN: ConoHa for Windows Server上で稼働する有料ソフトウェアである。JRA公式サイトからのスクレイピングを補完する、より安定したデータソースとして位置づけ、単勝・複勝・枠連・馬連の直前オッズを取得するために利用する。これにより、データ取得の冗長性を高める。  
* データ処理フローと特徴量生成:  
  * 前処理 (preprocessing): 収集した生データから、予測モデルが扱いやすい形式にデータを変換する。pandasを用いて、不要な文字の除去、データ型の統一（例：タイムを表す文字列1:35.5を秒数を表す浮動小数点数95.5に変換）、およびカテゴリ変数のラベルエンコーディング（例：性別 牡-\>0, 牝-\>1）などを実行する。処理済みデータはpreprocessedディレクトリに中間成果物として保存される。  
  * 特徴量生成 (feature\_engineering): 前処理済みデータを基に、予測に有効な特徴量を生成する。このプロセスはモデル性能を直接左右する重要な工程であり、以下の手法を含むものとする。  
    * 集計特徴量: 直近3, 5, 10レースといった期間を区切り、着順や獲得賞金の平均値・中央値・最大値・最小値などを算出する。  
    * 条件別特徴量: 特定の条件（コース距離、芝/ダート、競馬場、季節、馬場状態など）における過去成績を集計する。  
    * 相対的特徴量: 標準化をレース単位で実行し、特徴量を正規化する。これにより、特定のレースにおける競走馬との相対的な強さを表す指標を生成し、特徴量をレースのクラスやレベルから独立させる。

これらの精緻な特徴量を用い、次章で詳述する機械学習モデルの学習が行われる。

3.2 機械学習とシミュレーション

本セクションでは、システムの「知能」の中核をなす機械学習モデルの仕様を定義する。モデルの設計、学習プロセス、および性能評価の枠組みを明確に規定することにより、再現性が高く、継続的に改善可能な予測システムを構築するものとする。

* モデル仕様:  
  * アルゴリズム: 勾配ブースティング決定木の一種であるLightGBMを採用する。高い予測精度と高速な学習性能を両立する点が特徴である。  
  * 目的変数: モデルの予測対象は「1着になるかどうか」とする。単純な二値分類（win/loss）ではなく、モデルにより豊かなシグナルを提供するため、目的変数（target\_mod）は1着とのタイム差が0.0秒の馬（写真判定など）に対しても1を設定する。これにより、僅差の勝負を「実質的な勝利」として扱い、競争力の高い馬の特性をモデルがより精密に学習することを可能にする。  
* 学習プロセス:  
  * データ分割: 過去データを時系列に沿って厳密に分割する（例：学習用 2018-2022年、検証用 2023年1-9月、テスト用 2023年10-12月）。これにより、未来のデータを予測する本番運用環境を忠実に模倣する。  
  * 学習実行: 学習用データでモデルを訓練し、その過程で検証用データに対する性能（Log Loss）を監視する。「早期停止（Early Stopping）」を適用し、検証用データの性能が一定回数改善しなくなった時点で学習を自動的に打ち切ることで、過学習を抑制し、未知のデータに対する汎化性能を最大化する。  
  * モデル保存: 学習が完了したモデルは、予測時に再利用可能な形式（.pkl）で永続化される。  
* 性能評価とシミュレーション:  
  * オフライン検証: 学習および検証に一切使用していないテスト用データを用い、モデルの未知のデータに対する真の性能を評価する。  
  * シミュレーションロジック: モデルが予測した勝率と実際のオッズから期待値を計算する。期待値が指定した閾値（例：1.5）を超える馬券を買い続けた場合の的中率と回収率をシミュレートする。このシミュレーション結果の分析を通じて、最も収益性が高くなる最適な投票戦略（期待値の閾値など）を決定する。

このモデルの予測結果を基に、最終的にどのようにして実際の投票アクションに繋がるのかを、次のセクションで詳述する。

3.3 自動投票と運用

本セクションでは、モデルの予測という「情報」を具体的な「金銭的リターン」に転換するための、システムの自動化と運用に関する仕様を定義する。無人環境での安定稼働と確実なタスク実行こそが、本システムの価値を最大化する鍵となる。

* 実行環境とデプロイ:  
  * サーバー: ConoHa VPS上のLinux環境を本番環境として採用する。24時間365日の安定稼働と高速なインターネット接続が保証されるこの「常時稼働」環境は、スケジュールされたタスクの無人実行に必須である。  
  * プロセス管理: nohupコマンドを利用し、メインスクリプトをバックグラウンドプロセスとして実行する。これにより、SSH接続が切断された後もプロセスは継続して稼働し、レース開催日を通じた長時間の自動運用が可能となる。  
  * 設定管理: argparseライブラリを用い、スクリプトをコマンドライン引数で設定可能なアプリケーションとして設計する。これにより、実行日付や開発モードの指定などを柔軟に行うことができる。  
* スケジュール実行:  
  * OSレベル (cron): Linuxのcronデーモンを利用し、レース開催日の朝にマスター実行スクリプトを自動起動する。これはシステム全体の粗粒度なオーケストレーションを担い、手動での起動作業を完全に排除する。  
  * アプリケーションレベル (APSScheduler): スクリプト内部ではAPSSchedulerライブラリを利用し、各レースの発走時刻から逆算した精密なタイミング（例：発走5分前から1分おき）でオッズ取得などの細粒度タスクをスケジュール実行する。  
* 自動投票シーケンス:  
  * 事前準備: PlaywrightがIPATサイトに自動でログインし、投票可能な状態を維持する。  
  * 投票実行: 自動投票シーケンスは無人運用を前提とし、一時的なネットワーク問題やIPATサイトの構造変更に対応するための堅牢なエラーハンドリングを組み込む。期待値計算の結果、購入対象となった馬券の情報をPlaywrightに渡し、購入を実行する。すべての取引試行、成功、失敗は、後の監査のために詳細なコンテキストと共にログに記録されるものとする。  
* ロギングとテスト:  
  * 実行ログ: Pythonのloggingモジュールを用い、システムの全活動を詳細に記録する。スクリプトの実行状況、取得したオッズ、予測結果、投票内容、発生したエラーなどをタイムスタンプ付きでファイルに永続化し、運用状況の追跡と分析のための監査証跡を形成する。  
  * 品質保証: pytestフレームワークを用いたユニットテストおよび統合テストのスイートが、データ処理パイプラインとビジネスロジックの正当性を保証する。これらのテストは、継続的な開発および機能強化におけるシステムの完全性を維持し、リグレッションを防止するために不可欠である。